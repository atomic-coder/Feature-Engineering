{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7697424f-b391-4b01-aca0-0da917adfb65",
   "metadata": {},
   "source": [
    "# Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "766e2b5b-017b-4935-aed0-d94f9fb5c6a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de982936-c988-4ff1-b120-d650cc72acea",
   "metadata": {},
   "source": [
    "# To read images/ prepare feature vector and convert labels to one hot encoded vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9a07f925-eef7-439c-a3a1-f1786b749fa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Array Shape: (42000, 784)\n",
      "One-Hot Labels Shape: (42000, 10)\n"
     ]
    }
   ],
   "source": [
    "def one_hot_encode_labels(labels):\n",
    "    \"\"\"\n",
    "    Convert labels into one-hot encoded vectors.\n",
    "    \n",
    "    Parameters:\n",
    "        labels: List or 1D array of integers (0-9).\n",
    "\n",
    "    Returns:\n",
    "        one_hot_labels: 2D NumPy array of shape (n_samples, 10).\n",
    "    \"\"\"\n",
    "    n_samples = len(labels)\n",
    "    one_hot_labels = np.zeros((n_samples, 10))\n",
    "    one_hot_labels[np.arange(n_samples), labels] = 1\n",
    "    return one_hot_labels\n",
    "\n",
    "\n",
    "def extract_features(image):\n",
    "    \"\"\"\n",
    "    Extract features from a 28x28 image by flattening it into a 1D array.\n",
    "    \n",
    "    Parameters:\n",
    "        image: 2D NumPy array (28x28) - grayscale image.\n",
    "\n",
    "    Returns:\n",
    "        features: 1D NumPy array (784) - flattened image.\n",
    "    \"\"\"\n",
    "    return image.flatten()\n",
    "\n",
    "\n",
    "def preprocess_dataset(image_folder_path):\n",
    "    \"\"\"\n",
    "    Process images and labels for a digit recognition model.\n",
    "\n",
    "    Parameters:\n",
    "        image_folder_path: Path to the dataset folder containing subfolders 0-9.\n",
    "\n",
    "    Returns:\n",
    "        features_array: 2D NumPy array (n_samples, 784) - flattened image features.\n",
    "        one_hot_labels: 2D NumPy array (n_samples, 10) - one-hot encoded labels.\n",
    "    \"\"\"\n",
    "    features_list = []\n",
    "    labels_list = []\n",
    "\n",
    "    # Traverse folders (0-9)\n",
    "    for label in range(10):\n",
    "        label_folder = os.path.join(image_folder_path, str(label))\n",
    "        for filename in os.listdir(label_folder):\n",
    "            file_path = os.path.join(label_folder, filename)\n",
    "\n",
    "            # Open and process the image\n",
    "            image = Image.open(file_path).convert('L')  # Convert to grayscale since not all pictures are black and white like the dataset.\n",
    "            image = np.array(image) / 255.0  # Normalize pixel values to [0, 1]\n",
    "            features = extract_features(image)\n",
    "\n",
    "            # Append features and label\n",
    "            features_list.append(features)\n",
    "            labels_list.append(label)\n",
    "\n",
    "    # Convert to NumPy arrays\n",
    "    features_array = np.array(features_list)\n",
    "    one_hot_labels = one_hot_encode_labels(labels_list)\n",
    "\n",
    "    return features_array, one_hot_labels\n",
    "\n",
    "\n",
    "image_folder_path = r\"C:\\Users\\vijay\\Documents\\digit_rec\\trainingSet\\trainingSet\"  # Replace with your dataset path\n",
    "features_array, one_hot_labels = preprocess_dataset(image_folder_path)\n",
    "\n",
    "print(\"Feature Array Shape:\", features_array.shape)  # Should be (n_samples, 784)\n",
    "print(\"One-Hot Labels Shape:\", one_hot_labels.shape)  # Should be (n_samples, 10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fa0a0fd-cfe7-4d70-bd3f-83f02084eea8",
   "metadata": {},
   "source": [
    "# ReLu and it's derivative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e517480c-330e-4449-986e-5f5f6df9c5aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(x):\n",
    "    return np.maximum(0, x)\n",
    "\n",
    "def relu_derivative(x):\n",
    "    return np.where(x > 0, 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a0ad7e-fd35-4572-9068-d93ecd9ebc9b",
   "metadata": {},
   "source": [
    "# Softmax Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "cd3f9d76-5100-49aa-adab-d12a45f968c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    exp_x = np.exp(x - np.max(x, axis=1, keepdims=True))\n",
    "    return exp_x / np.sum(exp_x, axis=1, keepdims=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5913288f-90eb-459e-bdb9-f684a14922c5",
   "metadata": {},
   "source": [
    "# Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "958b70a4-6aad-4b8c-b51c-761f6caf57b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy_loss(y_true, y_pred):\n",
    "    # Categorical cross-entropy loss with a small value epsilon to avoid log(0)\n",
    "    return -np.mean(np.sum(y_true * np.log(y_pred + 1e-8), axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8f8c378-84ca-4064-aa05-16397a02138d",
   "metadata": {},
   "source": [
    "# Training the NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "bd7c1744-de58-4583-8fe9-e5d75d7deed7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50 - Loss: 0.6598, Accuracy: 0.8030\n",
      "Validation Loss: 0.3671, Validation Accuracy: 0.8874\n",
      "Learning rate: 0.001 \n",
      "\n",
      "Epoch 2/50 - Loss: 0.2855, Accuracy: 0.9168\n",
      "Validation Loss: 0.2408, Validation Accuracy: 0.9310\n",
      "Learning rate: 0.00095 \n",
      "\n",
      "Epoch 3/50 - Loss: 0.2028, Accuracy: 0.9413\n",
      "Validation Loss: 0.1895, Validation Accuracy: 0.9475\n",
      "Learning rate: 0.0009025 \n",
      "\n",
      "Epoch 4/50 - Loss: 0.1633, Accuracy: 0.9538\n",
      "Validation Loss: 0.1702, Validation Accuracy: 0.9532\n",
      "Learning rate: 0.000857375 \n",
      "\n",
      "Epoch 5/50 - Loss: 0.1413, Accuracy: 0.9611\n",
      "Validation Loss: 0.1603, Validation Accuracy: 0.9574\n",
      "Learning rate: 0.0008145062499999999 \n",
      "\n",
      "Epoch 6/50 - Loss: 0.1273, Accuracy: 0.9660\n",
      "Validation Loss: 0.1542, Validation Accuracy: 0.9618\n",
      "Learning rate: 0.0007737809374999998 \n",
      "\n",
      "Epoch 7/50 - Loss: 0.1172, Accuracy: 0.9694\n",
      "Validation Loss: 0.1508, Validation Accuracy: 0.9631\n",
      "Learning rate: 0.0007350918906249999 \n",
      "\n",
      "Epoch 8/50 - Loss: 0.1095, Accuracy: 0.9718\n",
      "Validation Loss: 0.1487, Validation Accuracy: 0.9640\n",
      "Learning rate: 0.0006983372960937497 \n",
      "\n",
      "Epoch 9/50 - Loss: 0.1039, Accuracy: 0.9738\n",
      "Validation Loss: 0.1481, Validation Accuracy: 0.9652\n",
      "Learning rate: 0.0006634204312890623 \n",
      "\n",
      "Epoch 10/50 - Loss: 0.0991, Accuracy: 0.9763\n",
      "Validation Loss: 0.1469, Validation Accuracy: 0.9655\n",
      "Learning rate: 0.0006302494097246091 \n",
      "\n",
      "Epoch 11/50 - Loss: 0.0951, Accuracy: 0.9779\n",
      "Validation Loss: 0.1478, Validation Accuracy: 0.9650\n",
      "Learning rate: 0.0005987369392383787 \n",
      "\n",
      "Epoch 12/50 - Loss: 0.0919, Accuracy: 0.9793\n",
      "Validation Loss: 0.1490, Validation Accuracy: 0.9655\n",
      "Learning rate: 0.0005688000922764596 \n",
      "\n",
      "Epoch 13/50 - Loss: 0.0893, Accuracy: 0.9805\n",
      "Validation Loss: 0.1515, Validation Accuracy: 0.9649\n",
      "Learning rate: 0.0005403600876626366 \n",
      "\n",
      "Epoch 14/50 - Loss: 0.0868, Accuracy: 0.9816\n",
      "Validation Loss: 0.1546, Validation Accuracy: 0.9663\n",
      "Learning rate: 0.0005133420832795048 \n",
      "\n",
      "Epoch 15/50 - Loss: 0.0849, Accuracy: 0.9822\n",
      "Validation Loss: 0.1575, Validation Accuracy: 0.9661\n",
      "Learning rate: 0.00048767497911552955 \n",
      "\n",
      "Epoch 16/50 - Loss: 0.0832, Accuracy: 0.9831\n",
      "Validation Loss: 0.1600, Validation Accuracy: 0.9662\n",
      "Learning rate: 0.000463291230159753 \n",
      "\n",
      "Epoch 17/50 - Loss: 0.0815, Accuracy: 0.9834\n",
      "Validation Loss: 0.1638, Validation Accuracy: 0.9662\n",
      "Learning rate: 0.00044012666865176535 \n",
      "\n",
      "Epoch 18/50 - Loss: 0.0800, Accuracy: 0.9840\n",
      "Validation Loss: 0.1669, Validation Accuracy: 0.9658\n",
      "Learning rate: 0.0004181203352191771 \n",
      "\n",
      "Epoch 19/50 - Loss: 0.0789, Accuracy: 0.9843\n",
      "Validation Loss: 0.1699, Validation Accuracy: 0.9661\n",
      "Learning rate: 0.0003972143184582182 \n",
      "\n",
      "Epoch 20/50 - Loss: 0.0778, Accuracy: 0.9849\n",
      "Validation Loss: 0.1726, Validation Accuracy: 0.9665\n",
      "Learning rate: 0.00037735360253530727 \n",
      "\n",
      "Epoch 21/50 - Loss: 0.0768, Accuracy: 0.9852\n",
      "Validation Loss: 0.1756, Validation Accuracy: 0.9671\n",
      "Learning rate: 0.0003584859224085419 \n",
      "\n",
      "Epoch 22/50 - Loss: 0.0757, Accuracy: 0.9857\n",
      "Validation Loss: 0.1784, Validation Accuracy: 0.9670\n",
      "Learning rate: 0.0003405616262881148 \n",
      "\n",
      "Epoch 23/50 - Loss: 0.0747, Accuracy: 0.9860\n",
      "Validation Loss: 0.1810, Validation Accuracy: 0.9675\n",
      "Learning rate: 0.000323533544973709 \n",
      "\n",
      "Epoch 24/50 - Loss: 0.0735, Accuracy: 0.9864\n",
      "Validation Loss: 0.1839, Validation Accuracy: 0.9675\n",
      "Learning rate: 0.00030735686772502356 \n",
      "\n",
      "Epoch 25/50 - Loss: 0.0723, Accuracy: 0.9871\n",
      "Validation Loss: 0.1859, Validation Accuracy: 0.9673\n",
      "Learning rate: 0.0002919890243387724 \n",
      "\n",
      "Epoch 26/50 - Loss: 0.0713, Accuracy: 0.9875\n",
      "Validation Loss: 0.1882, Validation Accuracy: 0.9671\n",
      "Learning rate: 0.00027738957312183375 \n",
      "\n",
      "Epoch 27/50 - Loss: 0.0703, Accuracy: 0.9878\n",
      "Validation Loss: 0.1903, Validation Accuracy: 0.9674\n",
      "Learning rate: 0.00026352009446574203 \n",
      "\n",
      "Epoch 28/50 - Loss: 0.0694, Accuracy: 0.9881\n",
      "Validation Loss: 0.1925, Validation Accuracy: 0.9671\n",
      "Learning rate: 0.00025034408974245495 \n",
      "\n",
      "Epoch 29/50 - Loss: 0.0687, Accuracy: 0.9883\n",
      "Validation Loss: 0.1946, Validation Accuracy: 0.9670\n",
      "Learning rate: 0.00023782688525533216 \n",
      "\n",
      "Epoch 30/50 - Loss: 0.0679, Accuracy: 0.9885\n",
      "Validation Loss: 0.1967, Validation Accuracy: 0.9669\n",
      "Learning rate: 0.00022593554099256555 \n",
      "\n",
      "Epoch 31/50 - Loss: 0.0672, Accuracy: 0.9886\n",
      "Validation Loss: 0.1986, Validation Accuracy: 0.9667\n",
      "Learning rate: 0.00021463876394293727 \n",
      "\n",
      "Epoch 32/50 - Loss: 0.0664, Accuracy: 0.9888\n",
      "Validation Loss: 0.2002, Validation Accuracy: 0.9667\n",
      "Learning rate: 0.00020390682574579038 \n",
      "\n",
      "Epoch 33/50 - Loss: 0.0657, Accuracy: 0.9889\n",
      "Validation Loss: 0.2019, Validation Accuracy: 0.9665\n",
      "Learning rate: 0.00019371148445850088 \n",
      "\n",
      "Epoch 34/50 - Loss: 0.0650, Accuracy: 0.9891\n",
      "Validation Loss: 0.2035, Validation Accuracy: 0.9663\n",
      "Learning rate: 0.00018402591023557584 \n",
      "\n",
      "Epoch 35/50 - Loss: 0.0642, Accuracy: 0.9890\n",
      "Validation Loss: 0.2045, Validation Accuracy: 0.9661\n",
      "Learning rate: 0.000174824614723797 \n",
      "\n",
      "Epoch 36/50 - Loss: 0.0634, Accuracy: 0.9891\n",
      "Validation Loss: 0.2063, Validation Accuracy: 0.9662\n",
      "Learning rate: 0.00016608338398760718 \n",
      "\n",
      "Epoch 37/50 - Loss: 0.0627, Accuracy: 0.9892\n",
      "Validation Loss: 0.2078, Validation Accuracy: 0.9662\n",
      "Learning rate: 0.0001577792147882268 \n",
      "\n",
      "Epoch 38/50 - Loss: 0.0621, Accuracy: 0.9893\n",
      "Validation Loss: 0.2090, Validation Accuracy: 0.9662\n",
      "Learning rate: 0.00014989025404881545 \n",
      "\n",
      "Epoch 39/50 - Loss: 0.0615, Accuracy: 0.9896\n",
      "Validation Loss: 0.2104, Validation Accuracy: 0.9662\n",
      "Learning rate: 0.00014239574134637466 \n",
      "\n",
      "Epoch 40/50 - Loss: 0.0611, Accuracy: 0.9898\n",
      "Validation Loss: 0.2115, Validation Accuracy: 0.9663\n",
      "Learning rate: 0.00013527595427905592 \n",
      "\n",
      "Epoch 41/50 - Loss: 0.0606, Accuracy: 0.9900\n",
      "Validation Loss: 0.2124, Validation Accuracy: 0.9662\n",
      "Learning rate: 0.00012851215656510312 \n",
      "\n",
      "Epoch 42/50 - Loss: 0.0601, Accuracy: 0.9900\n",
      "Validation Loss: 0.2133, Validation Accuracy: 0.9667\n",
      "Learning rate: 0.00012208654873684796 \n",
      "\n",
      "Epoch 43/50 - Loss: 0.0596, Accuracy: 0.9902\n",
      "Validation Loss: 0.2142, Validation Accuracy: 0.9668\n",
      "Learning rate: 0.00011598222130000556 \n",
      "\n",
      "Epoch 44/50 - Loss: 0.0590, Accuracy: 0.9902\n",
      "Validation Loss: 0.2153, Validation Accuracy: 0.9667\n",
      "Learning rate: 0.00011018311023500529 \n",
      "\n",
      "Epoch 45/50 - Loss: 0.0586, Accuracy: 0.9906\n",
      "Validation Loss: 0.2163, Validation Accuracy: 0.9663\n",
      "Learning rate: 0.00010467395472325501 \n",
      "\n",
      "Epoch 46/50 - Loss: 0.0581, Accuracy: 0.9907\n",
      "Validation Loss: 0.2174, Validation Accuracy: 0.9663\n",
      "Learning rate: 9.944025698709225e-05 \n",
      "\n",
      "Epoch 47/50 - Loss: 0.0577, Accuracy: 0.9908\n",
      "Validation Loss: 0.2185, Validation Accuracy: 0.9663\n",
      "Learning rate: 9.446824413773763e-05 \n",
      "\n",
      "Epoch 48/50 - Loss: 0.0572, Accuracy: 0.9909\n",
      "Validation Loss: 0.2192, Validation Accuracy: 0.9661\n",
      "Learning rate: 8.974483193085076e-05 \n",
      "\n",
      "Epoch 49/50 - Loss: 0.0568, Accuracy: 0.9909\n",
      "Validation Loss: 0.2202, Validation Accuracy: 0.9660\n",
      "Learning rate: 8.52575903343082e-05 \n",
      "\n",
      "Epoch 50/50 - Loss: 0.0564, Accuracy: 0.9909\n",
      "Validation Loss: 0.2209, Validation Accuracy: 0.9658\n",
      "Learning rate: 8.099471081759279e-05 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize neural network parameters\n",
    "input_size = 784\n",
    "hidden_layer_1_size = 512\n",
    "hidden_layer_2_size = 128\n",
    "output_size = 10\n",
    "learning_rate = 0.001\n",
    "epochs = 50\n",
    "batch_size = 128\n",
    "\n",
    "# Random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Initialize weights and biases\n",
    "w1 = np.random.randn(input_size, hidden_layer_1_size) * 0.01\n",
    "b1 = np.zeros((1, hidden_layer_1_size))\n",
    "\n",
    "w2 = np.random.randn(hidden_layer_1_size, hidden_layer_2_size) * 0.01\n",
    "b2 = np.zeros((1, hidden_layer_2_size))\n",
    "\n",
    "w3 = np.random.randn(hidden_layer_2_size, output_size) * 0.01\n",
    "b3 = np.zeros((1, output_size))\n",
    "\n",
    "# Adam optimizer state variables (momentum, velocity)\n",
    "m_w1, v_w1 = np.zeros_like(w1), np.zeros_like(w1)\n",
    "m_b1, v_b1 = np.zeros_like(b1), np.zeros_like(b1)\n",
    "m_w2, v_w2 = np.zeros_like(w2), np.zeros_like(w2)\n",
    "m_b2, v_b2 = np.zeros_like(b2), np.zeros_like(b2)\n",
    "m_w3, v_w3 = np.zeros_like(w3), np.zeros_like(w3)\n",
    "m_b3, v_b3 = np.zeros_like(b3), np.zeros_like(b3)\n",
    "\n",
    "beta1, beta2 = 0.9, 0.999  # Adam parameters\n",
    "epsilon = 1e-8  # For numerical stability\n",
    "\n",
    "# Learning rate decay\n",
    "lr_scheduler = lambda epoch: learning_rate * max(0.95 ** epoch, 1e-6)\n",
    "\n",
    "# Train-test split\n",
    "x_train, x_test, y_train, y_test = train_test_split(features_array, one_hot_labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(epochs):\n",
    "    epoch_loss = 0\n",
    "    epoch_accuracy = 0\n",
    "    num_batches = int(x_train.shape[0] / batch_size)\n",
    "    \n",
    "    for batch in range(num_batches):\n",
    "        # Get the current batch\n",
    "        start = batch * batch_size\n",
    "        end = start + batch_size\n",
    "        X_batch = x_train[start:end]\n",
    "        y_batch = y_train[start:end]\n",
    "        \n",
    "        # Forward pass\n",
    "        z1 = np.dot(X_batch, w1) + b1\n",
    "        a1 = relu(z1)\n",
    "        \n",
    "        z2 = np.dot(a1, w2) + b2\n",
    "        a2 = relu(z2)\n",
    "        \n",
    "        z3 = np.dot(a2, w3) + b3\n",
    "        y_pred = softmax(z3)\n",
    "\n",
    "        # Calculate loss\n",
    "        loss = cross_entropy_loss(y_batch, y_pred)\n",
    "        epoch_loss += loss\n",
    "        \n",
    "        # Calculate accuracy\n",
    "        accuracy = np.mean(np.argmax(y_pred, axis=1) == np.argmax(y_batch, axis=1))\n",
    "        epoch_accuracy += accuracy\n",
    "\n",
    "        # Backpropagation\n",
    "        # Output layer gradients\n",
    "        dz3 = y_pred - y_batch  # Gradient of loss w.r.t output layer\n",
    "        dw3 = np.dot(a2.T, dz3) / batch_size\n",
    "        db3 = np.sum(dz3, axis=0, keepdims=True) / batch_size\n",
    "        \n",
    "        # Hidden layer 2 gradients\n",
    "        dz2 = np.dot(dz3, w3.T) * relu_derivative(a2)\n",
    "        dw2 = np.dot(a1.T, dz2) / batch_size\n",
    "        db2 = np.sum(dz2, axis=0, keepdims=True) / batch_size\n",
    "        \n",
    "        # Hidden layer 1 gradients\n",
    "        dz1 = np.dot(dz2, w2.T) * relu_derivative(a1)\n",
    "        dw1 = np.dot(X_batch.T, dz1) / batch_size\n",
    "        db1 = np.sum(dz1, axis=0, keepdims=True) / batch_size\n",
    "        \n",
    "        # Adam optimizer parameter update\n",
    "        for param, grad, m, v, lr in zip([w1, w2, w3], [dw1, dw2, dw3], [m_w1, m_w2, m_w3], [v_w1, v_w2, v_w3], [lr_scheduler(epoch)] * 3):\n",
    "            m = beta1 * m + (1 - beta1) * grad\n",
    "            v = beta2 * v + (1 - beta2) * np.square(grad)\n",
    "            m_hat = m / (1 - beta1 ** (epoch + 1))  # Bias correction\n",
    "            v_hat = v / (1 - beta2 ** (epoch + 1))  # Bias correction\n",
    "            param -= lr * m_hat / (np.sqrt(v_hat) + epsilon)\n",
    "\n",
    "        for param, grad, m, v, lr in zip([b1, b2, b3], [db1, db2, db3], [m_b1, m_b2, m_b3], [v_b1, v_b2, v_b3], [lr_scheduler(epoch)] * 3):\n",
    "            m = beta1 * m + (1 - beta1) * grad\n",
    "            v = beta2 * v + (1 - beta2) * np.square(grad)\n",
    "            m_hat = m / (1 - beta1 ** (epoch + 1))  # Bias correction\n",
    "            v_hat = v / (1 - beta2 ** (epoch + 1))  # Bias correction\n",
    "            param -= lr * m_hat / (np.sqrt(v_hat) + epsilon)\n",
    "\n",
    "    # Epoch metrics\n",
    "    print(f\"Epoch {epoch + 1}/{epochs} - Loss: {epoch_loss/num_batches:.4f}, Accuracy: {epoch_accuracy/num_batches:.4f}\")\n",
    "    \n",
    "    # Validation loss and accuracy after every epoch\n",
    "    z1_val = np.dot(x_test, w1) + b1\n",
    "    a1_val = relu(z1_val)\n",
    "    z2_val = np.dot(a1_val, w2) + b2\n",
    "    a2_val = relu(z2_val)\n",
    "    z3_val = np.dot(a2_val, w3) + b3\n",
    "    y_pred_val = softmax(z3_val)\n",
    "    \n",
    "    val_loss = cross_entropy_loss(y_test, y_pred_val)\n",
    "    val_accuracy = np.mean(np.argmax(y_pred_val, axis=1) == np.argmax(y_test, axis=1))\n",
    "    print(f\"Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}\")\n",
    "    print(f\"Learning rate: {lr}\",\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c00ee62-7bdf-40d9-8b60-ec790ccde9a9",
   "metadata": {},
   "source": [
    "# TensorFlow model for comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "b597eb26-30cb-418a-9eaf-793e97fbea6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8048 - loss: 0.6761 - val_accuracy: 0.9421 - val_loss: 0.2018\n",
      "Epoch 2/50\n",
      "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9519 - loss: 0.1596 - val_accuracy: 0.9583 - val_loss: 0.1385\n",
      "Epoch 3/50\n",
      "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9698 - loss: 0.1003 - val_accuracy: 0.9657 - val_loss: 0.1214\n",
      "Epoch 4/50\n",
      "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9780 - loss: 0.0728 - val_accuracy: 0.9649 - val_loss: 0.1103\n",
      "Epoch 5/50\n",
      "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9849 - loss: 0.0512 - val_accuracy: 0.9681 - val_loss: 0.0990\n",
      "Epoch 6/50\n",
      "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9871 - loss: 0.0414 - val_accuracy: 0.9670 - val_loss: 0.1059\n",
      "Epoch 7/50\n",
      "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9926 - loss: 0.0272 - val_accuracy: 0.9689 - val_loss: 0.1077\n",
      "Epoch 8/50\n",
      "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9950 - loss: 0.0214 - val_accuracy: 0.9737 - val_loss: 0.0932\n",
      "Epoch 9/50\n",
      "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9960 - loss: 0.0150 - val_accuracy: 0.9683 - val_loss: 0.1174\n",
      "Epoch 10/50\n",
      "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9961 - loss: 0.0141 - val_accuracy: 0.9727 - val_loss: 0.1058\n",
      "Epoch 11/50\n",
      "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9972 - loss: 0.0118 - val_accuracy: 0.9682 - val_loss: 0.1143\n",
      "Epoch 12/50\n",
      "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9978 - loss: 0.0087 - val_accuracy: 0.9738 - val_loss: 0.1029\n",
      "Epoch 13/50\n",
      "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9973 - loss: 0.0084 - val_accuracy: 0.9735 - val_loss: 0.1161\n",
      "Epoch 14/50\n",
      "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9991 - loss: 0.0047 - val_accuracy: 0.9736 - val_loss: 0.1128\n",
      "Epoch 15/50\n",
      "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9994 - loss: 0.0033 - val_accuracy: 0.9713 - val_loss: 0.1256\n",
      "Epoch 16/50\n",
      "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9973 - loss: 0.0092 - val_accuracy: 0.9655 - val_loss: 0.1467\n",
      "Epoch 17/50\n",
      "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9939 - loss: 0.0185 - val_accuracy: 0.9750 - val_loss: 0.1123\n",
      "Epoch 18/50\n",
      "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9982 - loss: 0.0070 - val_accuracy: 0.9721 - val_loss: 0.1299\n",
      "Epoch 19/50\n",
      "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9980 - loss: 0.0058 - val_accuracy: 0.9754 - val_loss: 0.1157\n",
      "Epoch 20/50\n",
      "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9997 - loss: 0.0020 - val_accuracy: 0.9767 - val_loss: 0.1166\n",
      "Epoch 21/50\n",
      "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.0780e-04 - val_accuracy: 0.9780 - val_loss: 0.1140\n",
      "Epoch 22/50\n",
      "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.4836e-04 - val_accuracy: 0.9777 - val_loss: 0.1159\n",
      "Epoch 23/50\n",
      "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.7789e-04 - val_accuracy: 0.9777 - val_loss: 0.1171\n",
      "Epoch 24/50\n",
      "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.5473e-04 - val_accuracy: 0.9777 - val_loss: 0.1185\n",
      "Epoch 25/50\n",
      "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.3596e-04 - val_accuracy: 0.9775 - val_loss: 0.1204\n",
      "Epoch 26/50\n",
      "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.1451e-04 - val_accuracy: 0.9779 - val_loss: 0.1217\n",
      "Epoch 27/50\n",
      "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.0265e-04 - val_accuracy: 0.9781 - val_loss: 0.1230\n",
      "Epoch 28/50\n",
      "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 9.4578e-05 - val_accuracy: 0.9782 - val_loss: 0.1242\n",
      "Epoch 29/50\n",
      "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.7154e-05 - val_accuracy: 0.9783 - val_loss: 0.1251\n",
      "Epoch 30/50\n",
      "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.6326e-05 - val_accuracy: 0.9774 - val_loss: 0.1263\n",
      "Epoch 31/50\n",
      "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.3483e-05 - val_accuracy: 0.9773 - val_loss: 0.1281\n",
      "Epoch 32/50\n",
      "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.8545e-05 - val_accuracy: 0.9779 - val_loss: 0.1288\n",
      "Epoch 33/50\n",
      "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.2701e-05 - val_accuracy: 0.9780 - val_loss: 0.1310\n",
      "Epoch 34/50\n",
      "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.5404e-05 - val_accuracy: 0.9775 - val_loss: 0.1314\n",
      "Epoch 35/50\n",
      "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.1463e-05 - val_accuracy: 0.9777 - val_loss: 0.1328\n",
      "Epoch 36/50\n",
      "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.8356e-05 - val_accuracy: 0.9779 - val_loss: 0.1340\n",
      "Epoch 37/50\n",
      "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.2015e-05 - val_accuracy: 0.9777 - val_loss: 0.1359\n",
      "Epoch 38/50\n",
      "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.8228e-05 - val_accuracy: 0.9776 - val_loss: 0.1362\n",
      "Epoch 39/50\n",
      "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9985 - loss: 0.0056 - val_accuracy: 0.9664 - val_loss: 0.1481\n",
      "Epoch 40/50\n",
      "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9915 - loss: 0.0267 - val_accuracy: 0.9727 - val_loss: 0.1319\n",
      "Epoch 41/50\n",
      "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9966 - loss: 0.0094 - val_accuracy: 0.9748 - val_loss: 0.1281\n",
      "Epoch 42/50\n",
      "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9989 - loss: 0.0035 - val_accuracy: 0.9774 - val_loss: 0.1274\n",
      "Epoch 43/50\n",
      "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9998 - loss: 0.0012 - val_accuracy: 0.9771 - val_loss: 0.1251\n",
      "Epoch 44/50\n",
      "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.2908e-04 - val_accuracy: 0.9781 - val_loss: 0.1227\n",
      "Epoch 45/50\n",
      "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.4838e-04 - val_accuracy: 0.9787 - val_loss: 0.1233\n",
      "Epoch 46/50\n",
      "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.0693e-04 - val_accuracy: 0.9786 - val_loss: 0.1251\n",
      "Epoch 47/50\n",
      "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 9.7894e-05 - val_accuracy: 0.9785 - val_loss: 0.1266\n",
      "Epoch 48/50\n",
      "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.1001e-05 - val_accuracy: 0.9785 - val_loss: 0.1286\n",
      "Epoch 49/50\n",
      "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.7653e-05 - val_accuracy: 0.9786 - val_loss: 0.1299\n",
      "Epoch 50/50\n",
      "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.1225e-05 - val_accuracy: 0.9788 - val_loss: 0.1319\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x2164c2879e0>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "\n",
    "# Build the model\n",
    "model = Sequential([\n",
    "    Input(shape=(784,)),               # input layer\n",
    "    Dense(256, activation='relu'),     # hidden layer 1\n",
    "    Dense(64, activation='relu'),      # hidden layer 2\n",
    "    Dense(10, activation='softmax')    # output layer\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(x_train, y_train, epochs=50, batch_size=128, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca30092c-c294-4ea6-937f-594d583bccdd",
   "metadata": {},
   "source": [
    "# Attach image for prediction"
   ]
  },
  {
   "attachments": {
    "0ed27361-14c5-4208-97ed-b203985c6b0c.jpg": {
     "image/jpeg": "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"
    },
    "90c512bb-b67b-42f0-9ca3-5e5befdff812.jpg": {
     "image/jpeg": "/9j/4AAQSkZJRgABAQEAYABgAAD/2wBDAAYEBQYFBAYGBQYHBwYIChAKCgkJChQODwwQFxQYGBcUFhYaHSUfGhsjHBYWICwgIyYnKSopGR8tMC0oMCUoKSj/2wBDAQcHBwoIChMKChMoGhYaKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCj/wAARCAA2ADwDASIAAhEBAxEB/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/8QAHwEAAwEBAQEBAQEBAQAAAAAAAAECAwQFBgcICQoL/8QAtREAAgECBAQDBAcFBAQAAQJ3AAECAxEEBSExBhJBUQdhcRMiMoEIFEKRobHBCSMzUvAVYnLRChYkNOEl8RcYGRomJygpKjU2Nzg5OkNERUZHSElKU1RVVldYWVpjZGVmZ2hpanN0dXZ3eHl6goOEhYaHiImKkpOUlZaXmJmaoqOkpaanqKmqsrO0tba3uLm6wsPExcbHyMnK0tPU1dbX2Nna4uPk5ebn6Onq8vP09fb3+Pn6/9oADAMBAAIRAxEAPwD6U7UZ9+KTrSTSRQRF5mCgc81CQEij8vevGvjR4nuItWsdP0e9dJzt3InT73NavjX4gmSX+ytDO+5kOz5cHrxXnGreHbnTfFWmXmo7jNMgdg3Ylq2hHTUD3zwp9q/sG3N+5aYrySc961wePWqtkd2nW5H92rCms5rsBKpzTsCmqOKXFQAKBXEeOPDera7KEtLsQ254OHKn9K7bvSoTnimnqBy3hLwPp2gKJNv2i7xlnlw/5ZFcp8WYwfEumMBzsXp0+9XrCr8xPtXl/wAWMDWtPYYJwo/8eraLuB6Dp+f7Nt84xt7VNjnioNNBOlW+eu3+tTrxzWU1qIkAp1Mp9IYu35q5/X/F+jaC5jvrpI5v7hzXQmuX1rwdYatqQvLoFmznGeKcQOL1z4vtAGGnaY1yoGdwfH9K4C+17xZ4o1SK/TQ5vs8fRd455zX0VHo2nRxCP7HBtC4/1a/4VYitLWGMLFBEo9AgFaxmkB5LY+PPElpDHFP4clCKMZ80V02neP7eRo4762+yyMcbS2a7byIG+9DGf+AioW0+ydsm2h3euwVMpJsRJazpcwrJE2VYZqeo1RUGEAA9AKWs2Mex5pUGRRRQArdPxptFFADTwabnmiigB4oxRRQB/9k="
    },
    "c063c301-c608-4f63-80db-f206aff879f9.jpg": {
     "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/4gHYSUNDX1BST0ZJTEUAAQEAAAHIAAAAAAQwAABtbnRyUkdCIFhZWiAH4AABAAEAAAAAAABhY3NwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAQAA9tYAAQAAAADTLQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAlkZXNjAAAA8AAAACRyWFlaAAABFAAAABRnWFlaAAABKAAAABRiWFlaAAABPAAAABR3dHB0AAABUAAAABRyVFJDAAABZAAAAChnVFJDAAABZAAAAChiVFJDAAABZAAAAChjcHJ0AAABjAAAADxtbHVjAAAAAAAAAAEAAAAMZW5VUwAAAAgAAAAcAHMAUgBHAEJYWVogAAAAAAAAb6IAADj1AAADkFhZWiAAAAAAAABimQAAt4UAABjaWFlaIAAAAAAAACSgAAAPhAAAts9YWVogAAAAAAAA9tYAAQAAAADTLXBhcmEAAAAAAAQAAAACZmYAAPKnAAANWQAAE9AAAApbAAAAAAAAAABtbHVjAAAAAAAAAAEAAAAMZW5VUwAAACAAAAAcAEcAbwBvAGcAbABlACAASQBuAGMALgAgADIAMAAxADb/2wBDAAMCAgICAgMCAgIDAwMDBAYEBAQEBAgGBgUGCQgKCgkICQkKDA8MCgsOCwkJDRENDg8QEBEQCgwSExIQEw8QEBD/2wBDAQMDAwQDBAgEBAgQCwkLEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBD/wAARCAAcABwDASIAAhEBAxEB/8QAGwAAAgEFAAAAAAAAAAAAAAAAAwcIAQIEBgn/xAAqEAABAwMCBQMFAQAAAAAAAAABAgMEBQYRAAcSISIxQQhhgRMjMlGR0f/EABcBAAMBAAAAAAAAAAAAAAAAAAABAwL/xAAeEQABAwQDAAAAAAAAAAAAAAAAAQIhAwQREhMyQf/aAAwDAQACEQMRAD8A5qLCQOpWOepJelvZt5mZO3T3CpMVukw6LOkUumT0/eqjiUDqQg9kpz+R+BpEWTc7NnXLDuSTb8GtphkrTDnJ42Vq8FSTyOO+Dy02No9yrv3E3dqVeuysPTJDtu1BhloEpaYb+mMNtNjpbSO2EgDlouN0bEAJJxSX8yEtBtLpLgQnsgEkgfGcaxVAgnhVgaMySIqPPQBjOgrGFYwPjV29UQeDYNv7cpN43EzRq9dcS3YKmluOzpKeJCQkZ4QMjKj2Gnlt/dPpE2rYfq0OZfFx12XGcglRCI7bKXEgKWgFr+A51GlYCG+IAZ5aqglIGPH+6nVpcsKohn3DD9PkqK4uz7guumOttkoj1JpEhK1+EhTbacD3J0tFpPEccx7avABBP70MLVrTGa+jyf/Z"
    }
   },
   "cell_type": "markdown",
   "id": "a6ab1637-90c3-4e2a-9816-ad0c91e6f14f",
   "metadata": {},
   "source": [
    "## Instructions:\n",
    "\n",
    "1. Take a photo of the number.\n",
    "    \n",
    "2. Crop the photo such that there is not a lot of empty space between the number and the borders of the image.\n",
    "\n",
    "<div style=\"margin-left: 40px;\">\n",
    "\n",
    "![Screenshot 2024-11-30 162908.jpg](attachment:90c512bb-b67b-42f0-9ca3-5e5befdff812.jpg)\n",
    "\n",
    "</div>\n",
    "    \n",
    "4. Resize the image to 28x28 and convert it to a .jpg file.\n",
    "\n",
    "<div style=\"margin-left: 40px;\">\n",
    "\n",
    "![Screenshot 2024-11-30 162908.jpg](attachment:0ed27361-14c5-4208-97ed-b203985c6b0c.jpg)\n",
    "\n",
    "</div>\n",
    "    \n",
    "6. Invert the image's colours.\n",
    "\n",
    "<div style=\"margin-left: 40px;\">\n",
    "\n",
    "![image (2).jpg](attachment:c063c301-c608-4f63-80db-f206aff879f9.jpg)\n",
    "\n",
    "</div>\n",
    "    \n",
    "8. Copy the path of the image file into the cell and hit run!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "ff4eb963-fab5-413f-9c28-0d7a9e4889b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: 1\n"
     ]
    }
   ],
   "source": [
    "def predict(x_in):\n",
    "    # Forward pass through the network\n",
    "    z1 = np.dot(x_in, w1) + b1\n",
    "    a1 = relu(z1)\n",
    "    z2 = np.dot(a1, w2) + b2\n",
    "    a2 = relu(z2)\n",
    "    z3 = np.dot(a2, w3) + b3\n",
    "    y_pred = softmax(z3)\n",
    "\n",
    "    # Get the index of the maximum value (predicted number)\n",
    "    return np.argmax(y_pred)\n",
    "\n",
    "# Load the image\n",
    "image_path = r\"C:\\Users\\vijay\\Documents\\test_images\\image (2).jpg\"\n",
    "image = Image.open(image_path).convert('L')  # Convert to grayscale since not all pictures are black and white like the dataset.\n",
    "image = np.array(image) / 255.0  # Normalize pixel values to [0, 1]\n",
    "\n",
    "# Extract features (e.g., flatten the image)\n",
    "x_in = extract_features(image)\n",
    "\n",
    "# Predict the class of the input image\n",
    "predicted_class = predict(x_in)\n",
    "\n",
    "print(f\"Predicted class: {predicted_class}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
